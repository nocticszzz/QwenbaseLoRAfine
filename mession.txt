本次评测任务为细粒度片段级中文仇恨言论识别，基于给定的文本，任务的输入为社交媒体文本，输出为仇恨四元组，顺序依次为评论对象（Target）、论点（Argument）、目标群体（Targeted Group）、是否仇恨（Hateful）。具体说明如下：

评论对象（Target）：帖子的评述对象，如一个人或一个群体。当实例无具体目标时设为NULL。

论点（Argument）：包含对评论目标关键论点的信息片段。

目标群体（Targeted Group）：指包含仇恨信息的评论对象-论点对涉及的目标群体。标注的目标群体包括“地域”、“种族”、“性别”、“LGBTQ”、“其他”共5类。如样例1中包含了对LGBTQ群体和艾滋病群体的仇恨信息。

是否仇恨（Hateful）：评论对象-论点对是否构成了对某些群体的仇恨言论。

对于非仇恨文本和不包含特定群体的一般攻击性言论，同样需要对目标群体和观点进行抽取，并设为Non-hate。由于样本中可能有多个评论对象，因此可以包含多个四元组。 每个四元组中各个元素之间用" | "分割，并利用 [END] 结尾；如果一条样本中包含多个四元组，不同四元组之间利用 [SEP] 分割。请严格按照顺序和格式提交，不要省略空格，以免影响成绩。

下面提供两个数据样例：

输入： 你可真是头蠢驴，这都做不好。

输出： 你 | 蠢驴 | non-hate | non-hate [END]

输入： 老黑我是真的讨厌，媚黑的还倒贴。

输出： 老黑 | 讨厌 | Racism | hate [SEP] 媚黑的 | 倒贴 | Racism | hate [END]

将模型对测试集的输出内容按行保存到.txt文件中，如demo.txt文件。

本次评测鼓励参赛者充分发挥开源闭源大模型的能力来解决任务，同时也欢迎基于小模型进行建模。

评测数据
本次评测使用的中文仇恨言论四元组抽取数据集收集了贴吧、知乎等国内社交媒体平台的用户评论数据，为每条样本提供了高质量的二元分类标签，并对句子中的评论对象、论点和目标群体进行片段级标注。该数据集总计8000条中文数据，其中仇恨言论为4935，非仇恨言论为3065条。每条语句均包含一个或多个中文仇恨言论四元组，共计9405个，其中仇恨四元组5949个，非仇恨四元组3456个。

数据集的所有权归大连理工大学信息检索研究室所有。数据集包含有害违规内容示例，均不代表本团队立场。所有资源仅供科学研究使用，严禁商用。

评价指标
评价指标为提交结果和标准答案的硬匹配和软匹配分别的F1分数，以及两种方式的F1分数的平均分。计算方式与机器学习库sklearn一致。